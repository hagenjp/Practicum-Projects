{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "Hi, my name is Dmitry and I will be reviewing your project.\n",
    "  \n",
    "You can find my comments in colored markdown cells:\n",
    "  \n",
    "<div class=\"alert alert-success\">\n",
    "  If everything is done successfully.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-warning\">\n",
    "  If I have some (optional) suggestions, or questions to think about, or general comments.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-danger\">\n",
    "  If a section requires some corrections. Work can't be accepted with red comments.\n",
    "</div>\n",
    "  \n",
    "Please don't remove my comments, as it will make further review iterations much harder for me.\n",
    "  \n",
    "Feel free to reply to my comments or ask questions using the following template:\n",
    "  \n",
    "<div class=\"alert alert-info\">\n",
    "  For your comments and questions.\n",
    "</div>\n",
    "  \n",
    "First of all, thank you for turning in the project! You did an excellent job! I only had a couple of suggestions to improve the sanity check. The project is accepted. Keep up the good work on the next sprint! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning: Megaline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "You have access to behavior data about subscribers who have already switched to the new plans  For this classification task,I will develop a model that will pick the right plan.\n",
    "\n",
    "### Plan\n",
    "- Access and acess the data file\n",
    "- Split the source data into a training set, a validation set, and a test set.\n",
    "- Investigating the quality of different models by changing hyperparameters, 0.75 accuracy threshold\n",
    "- Checking the quality of test set\n",
    "- Sanity check the model\n",
    "- Reach conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all the libraries I need first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('/datasets/users_behavior.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>0.306472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.461100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used     is_ultra\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
       "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
       "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
       "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000     1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocessed this data previously so I was expecting it to look good and it does! we can move ahead with making the model datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Indeed, let's get started with modeling!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train,Valid,Test Split Using 80:10:10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the proportions of 80:10:10. I will first split the data into two parts the data_train (training dataset) and data_rem (remaining data). Then I will split the remaining data into the validation dataset and the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_rem = train_test_split(data, test_size = 0.8, random_state = 54321)\n",
    "data_valid, data_test = train_test_split(data_rem, test_size = 0.5, random_state = 54321)\n",
    "\n",
    "train_target = data_train['is_ultra']\n",
    "valid_target = data_validation['is_ultra']\n",
    "test_target = data_test['is_ultra']\n",
    "\n",
    "train_features = data_train.drop('is_ultra',axis = 1)\n",
    "valid_features = data_validation.drop('is_ultra',axis = 1)\n",
    "test_features = data_test.drop('is_ultra',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The data was split into train, validation and test sets. The proportion makes sense\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different model qualities, changing the Hyperparameters\n",
    "Now I will test DecisionTreeClassifier, RandomForestClassifier, and LogisticRegression, changing the hyperparameters for each to see which model can get the best accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - depth: 0.7433903576982893\n",
      "2 - depth: 0.7511664074650077\n",
      "3 - depth: 0.7791601866251944\n",
      "4 - depth: 0.7807153965785381\n",
      "5 - depth: 0.776049766718507\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,6):\n",
    "    model_DT = DecisionTreeClassifier(random_state=54321, max_depth=depth)\n",
    "    model_DT.fit(train_features,train_target)\n",
    "    predict = model_DT.predict(validation_features)\n",
    "    print( depth,\"- depth:\",accuracy_score(validation_target, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of estimators: 10 , accuracy_score: 0.7916018662519441\n",
      "number of estimators: 20 , accuracy_score: 0.7962674961119751\n",
      "number of estimators: 30 , accuracy_score: 0.7993779160186625\n",
      "number of estimators: 40 , accuracy_score: 0.7962674961119751\n",
      "number of estimators: 50 , accuracy_score: 0.7884914463452566\n",
      "number of estimators: 60 , accuracy_score: 0.7900466562986003\n",
      "number of estimators: 70 , accuracy_score: 0.7884914463452566\n",
      "number of estimators: 80 , accuracy_score: 0.7947122861586314\n",
      "number of estimators: 90 , accuracy_score: 0.8009331259720062\n",
      "number of estimators: 100 , accuracy_score: 0.7978227060653188\n"
     ]
    }
   ],
   "source": [
    "for est in range(10,101,10):\n",
    "    model_RF = RandomForestClassifier(random_state=54321, n_estimators = est)\n",
    "    model_RF.fit(train_features,train_target)\n",
    "    predict = model_RF.predict(validation_features)\n",
    "    print(\"number of estimators:\",est,\", accuracy_score:\",accuracy_score(validation_target, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7433903576982893\n"
     ]
    }
   ],
   "source": [
    "model_LR = LogisticRegression(random_state = 12345, solver='liblinear')\n",
    "model_LR.fit(train_features,train_target)\n",
    "predict = model_LR.predict(validation_features)\n",
    "print(accuracy_score(validation_target, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest is the clear winner here with an accuracy score of 80% which is great because our threshold is 75%. I will move forward with the RandomForestClassifier using 90 estimatiors with the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Excellent, you tried a couple of different models and did some hyperparameter tuning using the validation set\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for final model 0.7737169517884914\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(random_state = 54321, n_estimators = 90)\n",
    "final_model.fit(train_features, train_target)\n",
    "predict = final_model.predict(test_features)\n",
    "print(\"Accuracy for final model\",accuracy_score(test_target, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model was run with 80% of our dataset we were able to get 77% accuracy for our final model. Thats above our threshold and I would feel confident presenting this to my clients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The final model was evaluated on the test set! Train, validation and test sets were used correctly.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 0.7088716177317214\n",
      "Precision score: 0.7313890935065515\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall score:\",recall_score(test_target, predict, average='macro'))\n",
    "print(\"Precision score:\",precision_score(test_target, predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sanity check shows that our recall and precision are below our desired threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After investigating the data, creating datasets for training, testing, and validation. I optimized several models utilizing the hyperparameters and choosing the best accuracy from those results. I created a trained model and tested it with the test dataset comprised of 80% of our provided dataset, we achieved 77% accuracy with this model. n conclusion, our random forest model is trained and ready to use. I would proceed with some caution due to the sub par results from the sanity check returning below threshold precision and recall. However, it is a good start to a promising and useful model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "A couple of points:\n",
    "    \n",
    "1. While it's a good idea to look at different metrics, it doesn't make sense to apply a threshold chosen for one metric to another metric, they can measure very different things.\n",
    "    \n",
    "2. The correct value to use for `average` parameter of `recall_score` and `precision_score` in case of binary classification is the default `'binary'`: it doesn't do any averaging and just returns the result for the positive label, which is what we want: for binary classification it contains all the information we need. Averaging is only needed when there are more than two classes.\n",
    "    \n",
    "3. One way to sanity check our model is to compare it to some simple baseline and make sure it does better. For example, in this case we can make a simple constant model always predicting the majority class, it will have accuracy equal to the share of the majority class in the data (about 70% in this case). As our model does better than that, we can conclude that it has probably indeed learned something non-trivial :)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for your time reviewing my project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "You're welcome! :)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
